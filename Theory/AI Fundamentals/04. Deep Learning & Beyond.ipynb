{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Building Block : Artificial neurons\n",
    "    - Multiple inputs:\n",
    "        - Similar to multiple dendrites in brain for inbound signal \n",
    "    - Transfer function\n",
    "        - aggregates all weighted inputs\n",
    "        - Similar to Nucleus in brain for processing input signal \n",
    "    - activation functions\n",
    "        - converts aggregated values to output\n",
    "        - Similar to Nucleus in brain sending processed signal \n",
    "    - Single output\n",
    "        - Result of whole process\n",
    "        - Similar to single axon in brain for outbound signal..\n",
    "- Neural Network : When we take multiple artificial neurons and interconnect them in an organized way\n",
    "- Input layer : \n",
    "    - Entry point for data\n",
    "    - For image, each neuron is responsible for 1 pixel.\n",
    "- Hidden layer : \n",
    "    - Transformation point for data\n",
    "    - Weights and functions are responsible for the transformation\n",
    "- Output Layer:\n",
    "    - Transformed result\n",
    "    - Single value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary objects from Tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Initialize the sequential model (Linear stack of layers)\n",
    "model = Sequential()\n",
    "\n",
    "# Add the HIDDEN and OUTPUT layer, specify the input size and the activation function\n",
    "# Define multiple units. No. of Dimension = no. of features for each input data point\n",
    "model.add(Dense(units=32, input_dim=64, activation='relu')) # relu = REctified Linear Unit\n",
    "\n",
    "# Define the output unit as same as the class numbers\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Set guiding parameters for fitting procedures: optimizer, loss, performance metrics\n",
    "# Prepare the model for training (multi-class classification problem)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shallow Networks:\n",
    "    - 2-3 layers\n",
    "- Deep Neural Networks:\n",
    "    - 4+ layers\n",
    "- Feed-forward network:\n",
    "    - Signal travels unidirectionally\n",
    "    - From input to output\n",
    "    - Powerful\n",
    "    - Does not do well for data where order is important (text, sound, time-series)\n",
    "- Recurrent Neural Network:\n",
    "    - Takes current input\n",
    "    - All takes previously provided input from the past that is perceived in its memory \n",
    "    - Recognizes patterns in time\n",
    "    - Used for text, sound, time-series\n",
    "- Convolutional Neural Network:\n",
    "    - feed-forward network\n",
    "    - More Complex : Handle multi-dimensional data\n",
    "    - Recognizes patterns in space\n",
    "    - Used for images, text\n",
    "- Dense Layer : \n",
    "    - Fully connected layer\n",
    "    - each neurons from previous layer are connected to each neuron from the next layer and vise-versa\n",
    "    - `tensorflow.keras.layers.Dense`\n",
    "- Convolutional Layer: \n",
    "    - Works on multi-dimensional data\n",
    "    - Helps to extract features of image features invariant of position\n",
    "    - `tensorflow.keras.layers.Conv1D`, `Conv2D`, `...`\n",
    "- Dropout Layer: \n",
    "    - Randomly turn off fraction of nodes from previous layer\n",
    "    - Have regularization function\n",
    "    - Prevents overfitting\n",
    "    - `tensorflow.keras.layers.Dropout`\n",
    "- Pooling/sub-sampling: \n",
    "    - Reduce dimensionality of data by aggregation (like reducing resulation of picre)\n",
    "    - `tensorflow.keras.layers.MaxPooling1D`, `MaxPooling2D`, `...`\n",
    "- Flattening Layer:\n",
    "    - Wrangling operation\n",
    "    - From higher dimension to single dimensional space\n",
    "    - `tensorflow.keras.layers.Flatten`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the necessary objects from Tensorflow\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import (Dense, Conv2D, MaxPooling2D, Flatten)\n",
    "\n",
    "# # Initialize the model\n",
    "# model = Sequential()\n",
    "\n",
    "# # Create your 5-layer network (input specified implicitly with 1st layer)\n",
    "# model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "# # Reduce dimension\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "# # Wrangle computation from high to single dimension\n",
    "# model.add(Flatten())\n",
    "# # Output layer with 10 classes\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# # Set fitting hyper-parameters and compile the model\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Evaluate the model performance on unseen data\n",
    "# score = model.evaluate(x=x_test, y=y_test)\n",
    "# # Calculate loss\n",
    "# print('Test loss: %.2f' % score[0])\n",
    "# # Calculate accuracy\n",
    "# print('Test accuracy: %.2f %%' % (100*score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolution : Mathematical operation describing how signals are transformed by passing through systems of different characteristics\n",
    "- Inputs:\n",
    "    1. Input signal (video, audio...)\n",
    "    2. Transfer function of the processing system (lens, phone, tube...)\n",
    "- Process: Apply filter to our signal = Kernels = matrix of 0s and 1s\n",
    "- Result: The processed signal\n",
    "- Goal : extract particular features\n",
    "- Example: \n",
    "    - Simulating the \"telephone voice\"\n",
    "    - Image * Filter or kernel = Filtered transformed image\n",
    "    <center><img src=\"images/08.jpg\"  style=\"width: 200px, height: 200px;\"/></center>\n",
    "    - Vertical edge detection with sobel filter\n",
    "    <center><img src=\"images/09.jpg\"  style=\"width: 200px, height: 200px;\"/></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to find the right kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Traditional Computer Vision:\n",
    "    - Deterministic pre-processing and feature extraction, \n",
    "    - hard-coded by the Computer Vision engineer through hours and hours of experimentation with different approaches.\n",
    "- The Deep Learning Way:\n",
    "    - Get tons of labelled images and let the algorithm run\n",
    "    - The algorithm find the optimal kernels on its own.\n",
    "    - Kernels == feature extractors.\n",
    "    - Downside: Very data \"hungry\"!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

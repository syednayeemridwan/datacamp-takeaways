{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a regression model with more than one explanatory variable\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One explanatory variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One independent variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the independent variable is numeric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 intercept coefficient\n",
    "- 1 slope coefficient\n",
    "- Visualize with `regplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.formula.api import ols\n",
    "# model = ols(\"y_var ~ x_var_numeric\", data=df).fit()\n",
    "# print(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.regplot(x=\"x_var_numeric\",y=\"y_var\",data=df,ci=None)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the independent variable is categorical\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add `+ 0` when modeling with `ols()`\n",
    "- 1 intercept coefficient for each category\n",
    "- Visualize with `boxplot`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.formula.api import ols\n",
    "# model = ols(\"y_var ~ x_var_categorical + 0\", data=df).fit()\n",
    "# print(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(x=\"x_var_categorical\",\n",
    "#             y=\"y_var\",\n",
    "#             data=df,\n",
    "#             showmeans=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple explanatory variable\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 categorical independent variable\n",
    "- 1 numerical independent variable\n",
    "- 1 slope coefficient\n",
    "- 1 intercept coefficient for each category\n",
    "- Visualize with `scatterplot` and `axline` for each category \n",
    "- Since all slopes have same values, different lines will be parallel (hence, Parallel slopes regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.formula.api import ols\n",
    "# model = ols(\"y_var ~ x_var_numeric + x_var_categorical + 0\", data=df).fit()\n",
    "# print(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeffs = model.params\n",
    "# print(coeffs)\n",
    "\n",
    "# cat1, cat2, cat3, cat4, slope = coeffs\n",
    "\n",
    "# sns.scatterplot(x=\"x_var_numeric\",\n",
    "#                 y=\"y_var\",\n",
    "#                 hue=\"x_var_categorical\",\n",
    "#                 data=df)\n",
    "# plt.axline(xy1=(0, cat1), slope=slope, color=\"blue\")\n",
    "# plt.axline(xy1=(0, cat1), slope=slope, color=\"green\")\n",
    "# plt.axline(xy1=(0, cat1), slope=slope, color=\"red\")\n",
    "# plt.axline(xy1=(0, cat1), slope=slope, color=\"orange\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting parallel slopes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create possible combinations with cartesian product\n",
    "2. Make a dataframe with the combinations\n",
    "3. Use the created dataframe for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from itertools import product\n",
    "\n",
    "# col_numeric = np.arange(5, 61, 5)\n",
    "# col_categorical = df[\"category\"].unique()\n",
    "\n",
    "# combinations = product(col_numeric, col_categorical)\n",
    "\n",
    "# prediction_data = pd.DataFrame(combinations,\n",
    "#                                 columns=['col_numeric','col_categorical'])\n",
    "\n",
    "# print(expl_data_length)\n",
    "\n",
    "# prediction_data = prediction_data.assign(\n",
    "# predicted_col = model.predict(prediction_data)\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the predictions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create parallel lines for each category\n",
    "2. Create scatterplot for original dataset\n",
    "3. Create scatterplot for prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.axline(xy1=(0, cat1), slope=slope, color=\"blue\")\n",
    "# plt.axline(xy1=(0, cat2), slope=slope, color=\"green\")\n",
    "# plt.axline(xy1=(0, cat3), slope=slope, color=\"red\")\n",
    "# plt.axline(xy1=(0, cat4), slope=slope, color=\"orange\")\n",
    "\n",
    "# sns.scatterplot(x=\"x_var_numeric\",\n",
    "# y=\"y_var\",\n",
    "# hue=\"x_var_categorical\",\n",
    "# data=df)\n",
    "# sns.scatterplot(x=\"x_var_numeric\",\n",
    "# y=\"y_var\",\n",
    "# color=\"black\",\n",
    "# data=prediction_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually calculating predictions for simple linear regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract model parameters\n",
    "2. Create the predicted column with formula : `intercept + slope * explanatory_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeffs = model.params\n",
    "# print(coeffs)\n",
    "# intercept, slope = coeffs\n",
    "# explanatory_data = pd.DataFrame({\"to_be_predicted\": np.arange(5, 61, 5)})\n",
    "# prediction_data = explanatory_data.assign(\n",
    "# theoretical_prediction = intercept + slope * explanatory_data[\"to_be_predicted\"]\n",
    "# )\n",
    "# print(prediction_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually calculating predictions for multiple linear regression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract model parameters and intercepts\n",
    "2. Choose specific condition with `np.select()` [This acts like when ... then]\n",
    "3. Create the predicted column with formula : `intercept_of_choice + slope * explanatory_data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeffs = mdl_mass_vs_both.params\n",
    "# print(coeffs)\n",
    "\n",
    "# cat1, cat2, cat3, slope = coeffs\n",
    "\n",
    "# conditions = [\n",
    "# explanatory_data[\"class\"] == \"cat1\",\n",
    "# explanatory_data[\"class\"] == \"cat2\",\n",
    "# explanatory_data[\"class\"] == \"cat3\"\n",
    "# ]\n",
    "# choices = [cat1, cat2, cat3]\n",
    "# intercept = np.select(conditions, choices)\n",
    "# print(intercept)\n",
    "\n",
    "# prediction_data = explanatory_data.assign(\n",
    "# intercept = np.select(conditions, choices),\n",
    "# theoretical_prediction = intercept + slope * explanatory_data[\"to_be_predicted\"])\n",
    "# print(prediction_data)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coefficient of determination (R-squared): \n",
    "    - how well the linear regression line fits the observed values.\n",
    "    - Larger is beter\n",
    "    - extract : `print(model.rsquared)`\n",
    "    - More explanatory variables increases this value = overfitting\n",
    "    - Adjusted coefficient of determination penalizes more explanatory variables.\n",
    "        - Penalty is noticeable when R-square is small\n",
    "        - extract: `print(model.rsquared_adj)`\n",
    "- Residual standard error (RSE): \n",
    "    - the typical size of the residuals.\n",
    "    - Smaller is better\n",
    "    - RSE: `print(np.sqrt(model.mse_resid))`\n",
    "    - MSE: `print(model.mse_resid)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple logistic regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.formula.api import logit\n",
    "# model_without_interaction = logit(\"response ~ explanatory1 + explanatory2\", data=df).fit()\n",
    "# model_with_interaction = logit(\"response ~ explanatory1 * explanatory2\", data=df).fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_matrix = mmodel.pred_table()\n",
    "# print(conf_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import product\n",
    "# explanatory1 = some_values\n",
    "# explanatory2 = some_values\n",
    "# combinations = product(explanatory1, explanatory2)\n",
    "\n",
    "# explanatory_data = pd.DataFrame(combinations, columns=[\"explanatory1\",\"explanatory2\"])\n",
    "\n",
    "# prediction_data = explanatory_data.assign(\n",
    "#     predicted_col = model.predict(explanatory_data)\n",
    "#     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_data[\"most_likely_outcome\"] = np.round(prediction_data[\"predicted_probability\"])\n",
    "\n",
    "# sns.scatterplot(\n",
    "#     x= \"x_var\",\n",
    "#     y= \"y_var\",\n",
    "#     data=df,\n",
    "#     hue=\"class\")\n",
    "\n",
    "# sns.scatterplot(\n",
    "#     x= \"x_var\",\n",
    "#     y= \"y_var\",\n",
    "#     data=prediction_data,\n",
    "#     hue=\"most_likely_outcome\",\n",
    "#     legend = False)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian probability density function (PDF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normal distribution\n",
    "- The famous bell curve\n",
    "<center><img src=\"images/04.06.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import norm\n",
    "\n",
    "# x = np.arange(-4, 4.05, 0.05)\n",
    "\n",
    "# gauss_dist = pd.DataFrame({\n",
    "# \"x\": x,\n",
    "# \"gauss_pdf\": norm.pdf(x)}\n",
    "# )\n",
    "\n",
    "# sns.lineplot(x=\"x\",y=\"gauss_pdf\",data=gauss_dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian cumulative distribution function (CDF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cumulative of normal distribution (PDF)\n",
    "- Transformation of x values to probabilities\n",
    "<center><img src=\"images/04.07.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(-4, 4.05, 0.05)\n",
    "\n",
    "# gauss_dist = pd.DataFrame({\n",
    "# \"x\": x,\n",
    "# \"gauss_pdf\": norm.pdf(x),\n",
    "# \"gauss_cdf\": norm.cdf(x)}\n",
    "# )\n",
    "# sns.lineplot(x=\"x\",y=\"gauss_cdf\",data=gauss_dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian inverse CDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inverse of CDF = Percent Point Function (PPF)\n",
    "- Also known as quantile function\n",
    "- Back Transforms of probabilities to x values\n",
    "<center><img src=\"images/04.08.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = np.arange(0.001, 1, 0.001)\n",
    "\n",
    "# gauss_dist_inv = pd.DataFrame({\n",
    "# \"p\": p,\n",
    "# \"gauss_inv_cdf\": norm.ppf(p)}\n",
    "# )\n",
    "\n",
    "# sns.lineplot(x=\"p\",y=\"gauss_inv_cdf\",data=gauss_dist_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic PDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quite similar to Gaussian PDF\n",
    "- Fatter ends\n",
    "<center><img src=\"images/04.09.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import logistic\n",
    "\n",
    "# x = np.arange(-4, 4.05, 0.05)\n",
    "\n",
    "# logistic_dist = pd.DataFrame({\n",
    "# \"x\": x,\n",
    "# \"log_pdf\": logistic.pdf(x)}\n",
    "# )\n",
    "\n",
    "# sns.lineplot(x=\"x\",y=\"log_pdf\",data=logistic_dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic CDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic distribution CDF is also called the logistic function.\n",
    "- `y_pred = logistic.cdf(intercept + slope * x_actual)`\n",
    "<center><img src=\"images/04.07.svg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import logistic\n",
    "# from scipy.stats import logistic\n",
    "\n",
    "# # Create x ranging from minus ten to ten in steps of 0.1\n",
    "# x = np.arange(-10, 10.1, 0.1)\n",
    "\n",
    "# # Create logistic_dist\n",
    "# logistic_dist = pd.DataFrame({\"x\": x,\n",
    "#                               \"log_cdf\": logistic.cdf(x),\n",
    "#                               \"log_cdf_man\": 1 / (1 + np.exp(-x))})\n",
    "\n",
    "# # Using logistic_dist, plot log_cdf vs. x\n",
    "# sns.lineplot(x = \"x\", y= \"log_cdf\", data = logistic_dist)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic distribution inverse CDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic distribution inverse CDF is also called the logit function.\n",
    "<center><img src=\"images/04.08.svg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create p ranging from 0.001 to 0.999 in steps of 0.001\n",
    "# p = np.arange(0.001, 1, 0.001)\n",
    "\n",
    "# # Create logistic_dist_inv\n",
    "# logistic_dist_inv = pd.DataFrame({\"p\": p,\n",
    "#                                   \"logit\": logistic.ppf(p),\n",
    "#                                   \"logit_man\": np.log(p / (1 - p))})\n",
    "\n",
    "# # Using logistic_dist_inv, plot logit vs. p\n",
    "# sns.lineplot(x = \"p\", y = \"logit\", data = logistic_dist_inv)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How logistic regression works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sum of squares is a poor choice for classification\n",
    "- Better metrics : Likelihood\n",
    "- Likelihood \n",
    "    - find maximum value of probability for optimization\n",
    "    - formula for all: `likelihood = np.sum(y_pred * y_actual + (1- y_pred) * (1- y_actual))`\n",
    "    - Evaulates to a higher value when predicted value is close to actual value\n",
    "- Log-likelihood \n",
    "    - Computing likelihood involves adding many very small numbers, leading to numerical error.\n",
    "    - Log-likelihood is easier to compute.\n",
    "    - Maximizing log-likelihood is the same as minimizing negative log-likelihood `-np.sum(log_likelihood)`\n",
    "    - `log_likelihood =  np.log(y_pred) * y_actual + np.log(1 - y_pred) * (1 - y_actual)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.optimize import minimize\n",
    "\n",
    "# # Complete the function\n",
    "# def calc_neg_log_likelihood(coeffs):\n",
    "#     # Unpack coeffs\n",
    "#     intercept, slope = coeffs\n",
    "#     # Calculate predicted y-values\n",
    "#     y_pred = logistic.cdf(intercept + slope * x_actual) # Transformation to logistic probability\n",
    "#     # Calculate log-likelihood\n",
    "#     log_likelihood = np.log(y_pred) * y_actual + np.log(1 - y_pred) * (1 - y_actual)\n",
    "#     # Calculate negative sum of log_likelihood\n",
    "#     neg_sum_ll = -np.sum(log_likelihood)\n",
    "#     # Return negative sum of log_likelihood\n",
    "#     return neg_sum_ll\n",
    "  \n",
    "# # Call minimize on calc_sum_of_squares  \n",
    "# print(minimize(fun=calc_neg_log_likelihood,\n",
    "#                x0=[0,0]))\n",
    "\n",
    "# # Compare the output with the logit() call.\n",
    "# print(logit(\"y_var ~ x_var\", data=churn).fit().params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

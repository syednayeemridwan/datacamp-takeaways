{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spider Class Skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import scrapy\n",
    "\n",
    "class YourSpider(scrapy.Spider):\n",
    "  name = \"your_spider\"\n",
    "\n",
    "  def start_requests(self):\n",
    "    yield scrapy.Request( url = url, callback = self.parse )\n",
    "\n",
    "  def parse(self, response):\n",
    "    result = response.body\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # `start_requests` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "  def start_requests( self ):\n",
    "    urls = [\"https://www.datacamp.com\" ,\"https://scrapy.org\"]\n",
    "    for url in urls:\n",
    "      yield scrapy.Request( url = url, callback = self.parse ) // the real request \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `parse` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def parse( self, response ):\n",
    "    some_file = 'some_file.html'\n",
    "    with open( html_file, 'wb' ) as f:\n",
    "        f.write( response.body ) // save the response\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Referencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import scrapy\n",
    "\n",
    "class YourSpider( scrapy.Spider ):\n",
    "  name = \"your_spider\"\n",
    "\n",
    "  def start_requests( self ):\n",
    "    self.print_msg( \"Hello World!\" ) // calling this classe's method with parameter\n",
    "\n",
    "  def parse( self, response ):\n",
    "    pass\n",
    "\n",
    "  def print_msg( self, msg ):\n",
    "    print( \"Calling start_requests in YourSpider prints out:\", msg ) // defining a class method that takes msg as argument\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting into spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import scrapy\n",
    "\n",
    "class DCspider( scrapy.Spider ):\n",
    "  name = 'dcspider'\n",
    "\n",
    "  def start_requests( self ):\n",
    "    yield scrapy.Request( url = url_short, callback = self.parse )\n",
    "\n",
    "  def parse( self, response ): // response will be passed here from start_request\n",
    "    author_names = response.css('p.course-block__author-name::text').extract()\n",
    "    return author_names\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Web Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class Some_Spider_Class(scrapy.Spider):\n",
    "  name = \"some_spider_class\"\n",
    "\n",
    "  def start_requests( self ):\n",
    "    url = 'https://www.datacamp.com/courses/all'\n",
    "    yield scrapy.Request( url = url,  callback = self.parse_front )\n",
    "\n",
    "  def parse_front( self, response ):\n",
    "    course_blocks = response.css( 'div.course-block' )\n",
    "    course_links = course_blocks.xpath( './a/@href' )\n",
    "    links_to_follow = course_links.extract()\n",
    "    for url in links_to_follow:\n",
    "      yield response.follow( url = url, callback = self.parse_pages )\n",
    "\n",
    "\n",
    "  def parse_pages( self, response ):\n",
    "    crs_title = response.xpath('//h1[contains(@class,\"title\")]/text()')\n",
    "    crs_title_ext = crs_title.extract_first().strip()\n",
    "    ch_titles = response.css( 'h4.chapter__title::text' )\n",
    "    ch_titles_ext = [t.strip() for t in ch_titles.extract()]\n",
    "    dc_dict[ crs_title_ext ] = ch_titles_ext\n",
    "\n",
    "\n",
    "dc_dict = dict()\n",
    "\n",
    "process = CrawlerProcess()\n",
    "\n",
    "process.crawl(Some_Spider_Class)\n",
    "\n",
    "process.start()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

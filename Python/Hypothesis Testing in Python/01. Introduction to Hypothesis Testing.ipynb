{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We create two scenarios : Scenario A and Scenario B\n",
    "- We create samples for the 2 scenarios\n",
    "- calculate means from the samples \n",
    "- We calculate which scenario is good from the means\n",
    "    - Now the question is, the result we got, is it due to random chance? or is it because of high probability (meaningful)?\n",
    "    - To answer this, we need to hypothesis test on the mean\n",
    "- For hypothesis testing:\n",
    "    - Determine whether sample statistics are close to or far away from expected or\"hypothesized\" values)\n",
    "    - We only have a sample\n",
    "    - We need to resample the sample many times (Bootstrapping)\n",
    "    - we save the mean of each resample\n",
    "    - We create a distribution of all resampled means\n",
    "    - We calculate standard deviation (standard error), mean of the distribution\n",
    "    - Now using these statistics, we convert our A/B test's means to z-score \n",
    "        - z-score allows us to standardize any value for comparison\n",
    "        - It compares all values with a distribution(PDF) that have mean = 0 and std = 1. This is also called z-distribution\n",
    "        - formula : `z-score = (value - mean) / standard deviation`\n",
    "        - formula : `z-score = (sample mean - assumed mean) / std of bootstrap mean`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a bootstrap distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # Step 3. Repeat steps resampling & averaging many times, appending to a list\n",
    "# bootstrap_distn = []\n",
    "# for i in range(5000):\n",
    "#     resampled_mean = np.mean(sample_df.sample(frac=1, replace=True)['col'])\n",
    "#     bootstrap_distn.append(resampled_mean)\n",
    "\n",
    "# std_error_from_bootstrapped_means = np.std(bootstrap_distn, ddof=1)\n",
    "\n",
    "# sample_mean = sample_df['col'].mean()\n",
    "# z_score = (sample_mean - mean_of_hypothesis_proposed) / std_error_from_bootstrapped_means"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the bootstrap distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(so_boot_distn, bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A statement about an unknown population parameter \n",
    "- We need to infer it from data\n",
    "- A test of two competing hypotheses\n",
    "    - Null hypothesis (H0) : the existing idea\n",
    "    - Alternative hypothesis (HA ) : new \"challenger\" idea of the researcher\n",
    "    - Initially assumed that null hypothesis is true\n",
    "    - Assumption is only changed if sample provides evidence to reject the null\n",
    "    - Reject the null = Alternative hypothesis is true\n",
    "    - Fail to reject the null = Alternative hypothesis is false\n",
    "    - Whether to reject or not depends on significance level\n",
    "    - p values:\n",
    "        - measure the strength of support for null hypothesis (probability that the null is true)\n",
    "        - Large p-values mean that our statistic is producing a result that is likely not in the tail of null distribution = Interpretation is random chance\n",
    "        - Small p-values mean that our statistic is producing a result that is likely in the tail of null distribution = Interpretation is not random chance\n",
    "        - p value is calculated from z-value\n",
    "\n",
    "        <center><img src=\"images/01.05.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "- Example:\n",
    "    - Fact : Previous research shows that 35% of software developers started programming as children\n",
    "    - Question : greater proportion of data scientists starting programming as children?\n",
    "    - H0 : The proportion of data scientists starting programming as children is 35%\n",
    "    - HA : The proportion of data scientists starting programming as children is greater than 35%\n",
    "- Type of hypothesis tests\n",
    "    - One tailed\n",
    "        - alternative greater than null (right-tailed)\n",
    "        - alternative less than null (left-tailed)\n",
    "    - Two tailed\n",
    "        - alternative different from null\n",
    "- Significance level\n",
    "    - Cut-off point to determine whether to reject the hypothesis or not\n",
    "    - depends on dataset\n",
    "    - Common values of α are 0.2 , 0.1 , 0.05 , and 0.01\n",
    "    - If p ≤ α, reject H , else fail to reject H\n",
    "    - α should be set prior to conducting the hypothesis test\n",
    "- Confidence intervals\n",
    "    - For a significance level of α, it's common to choose a confidence interval level of 1 - α\n",
    "        - α = 0.05 → 95% confidence interval\n",
    "- Types of errors\n",
    "    - Type 1 : False Positive\n",
    "        - May exist if p ≤ α\n",
    "    - Type 2 : False Negative\n",
    "        - May exist if p> α\n",
    "        <center><img src=\"images/01.09.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left-Tailed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import norm\n",
    "# norm.cdf(z_score, loc=0, scale=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right-Tailed Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import norm\n",
    "# 1 - norm.cdf(z_score, loc=0, scale=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.05\n",
    "# p_value <= alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# lower = np.quantile(bootstrap_distn, 0.025)\n",
    "# upper = np.quantile(bootstrap_distn, 0.975)\n",
    "# print((lower, upper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc575bfddb5c8ca4bb6a4f4dcdd32abc104b5fa4177361381c432fff36ce3e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying model fitness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determine how good a model is\n",
    "- the model's goodness is expressed in quantity / number\n",
    "1. Coefficient of determination\n",
    "    - Sometimes called \"r-squared\" or \"R-squared\".\n",
    "    - quantifies relationship between variables\n",
    "    - The proportion of the variance in the response variable that is predictable from the explanatory variable (How much of the response variable can be explained by explanatory variable)\n",
    "    - 1 means a perfect fit, 0 means the worst possible fit\n",
    "    - get the value : `print(model.rsquared)`\n",
    "2. Residual standard error (RSE) \n",
    "    - A \"typical\" difference between prediction and observed responses\n",
    "    - It has the same unit as the response variable.\n",
    "    - get the value : `print(np.sqrt(model.mse_resid))`\n",
    "    - Degrees of freedom =  the number of observations minus the number of model coefficients.\n",
    "    - a model has an RSE of 74  means : The difference between predicted and observed values is typically about 74 unit.\n",
    "<center><img src=\"images/03.01.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "\n",
    "3. Mean Squared error (MSE)\n",
    "    - MSE = RSEÂ²\n",
    "    - get the value : `print(model.mse_resid)`\n",
    "4. Root-mean-square error (RMSE)\n",
    "    - get the value : `print(np.sqrt(model.mse_resid))`\n",
    "5. Correlation vs Coefficient of determination\n",
    "    - The coefficient of determination for a simple linear regression model is the correlation squared."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating RSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals_sq = model.resid ** 2\n",
    "# resid_sum_of_sq = sum(residuals_sq)\n",
    "# deg_freedom = len(df.index) - deg_of_freedom # Degree of freedom used\n",
    "# rse = np.sqrt(resid_sum_of_sq/deg_freedom)\n",
    "# print(\"rse :\", rse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals_sq = model.resid ** 2\n",
    "# resid_sum_of_sq = sum(residuals_sq)\n",
    "# n_obs = len(df.index) # Number of observations used\n",
    "# rmse = np.sqrt(resid_sum_of_sq/n_obs)\n",
    "# print(\"rmse :\", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual properties of a good fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Residuals are normally distributed\n",
    "- The mean of the residuals is zero\n",
    "<center><img src=\"images/03.04.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Diagnostics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals vs. fitted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lowess trend line = blue line\n",
    "- smooth curve following the data\n",
    "- useful for visualizing trends\n",
    "- if residuals are normally distributed, then the blue line will be close to 0 dotted line\n",
    "- Shows positive or negative as the fitted values change (on the Y-axis)\n",
    "<center><img src=\"images/03.05.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.residplot(x=\"x_var\", y=\"y_var\", data=df, lowess=True)\n",
    "# plt.xlabel(\"Fitted values\")\n",
    "# plt.ylabel(\"Residuals\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Q Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shows whether or not the residuals follow a normal distribution\n",
    "- X-axis shows theoretical quantiles\n",
    "- Y-axis shows quantiles derived from the dataset\n",
    "- If the points trek along the straight line the residuals are normally distributed\n",
    "- Most deviated points indicate the highest residuals and their rows\n",
    "<center><img src=\"images/03.06.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.api import qqplot\n",
    "# qqplot(data=model.resid, fit=True, line=\"45\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale-location plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Square root of normalized standard residuals versus the fitted values\n",
    "- Shows whether the size of the residuals gets bigger or smaller as the fitted values change\n",
    "- Constant size = smooth line, dynamic size = line with ups and downs\n",
    "- smooth = good, too many ups and downs = bad\n",
    "<center><img src=\"images/03.07.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_norm_residuals = model.get_influence().resid_studentized_internal # Normalized residuals\n",
    "# model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
    "# sns.regplot(x=model.fittedvalues, y=model_norm_residuals_abs_sqrt, ci=None, lowess=True)\n",
    "# plt.xlabel(\"Fitted values\")\n",
    "# plt.ylabel(\"Sqrt of abs val of stdized residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_norm_residuals_abs_sqrt=np.sqrt(np.abs(residuals))\n",
    "\n",
    "# plt.figure(figsize=(7,7))\n",
    "# sns.regplot(predictions.reshape(-1), model_norm_residuals_abs_sqrt,\n",
    "#               scatter=True,\n",
    "#               lowess=True,\n",
    "#               line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "# plt.ylabel(\"Standarized residuals\")\n",
    "# plt.xlabel(\"Fitted value\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explanatory variables that are extreme\n",
    "    - easy to visualize them\n",
    "- points lie a long way from predictions\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leverage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quantifies how extreme the explanatory variable values are\n",
    "- Simple if there is only one explanatory variable (Just find minimum and maximum)\n",
    "- Mathematically complex for multiple explanatory variable (How do you consider which points are minimum or maximum according to a hyperdimension?)\n",
    "- Highly leveraged points are the ones with explanatory variables that are furthest away from the others.\n",
    "- `hat_diag` in `summary_frame()` stores the leverage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Measures how much the model would change if you leave the observation out of the dataset when modeling.\n",
    "- Influence of each observation is based on the size of the residuals and the leverage\n",
    "- See all influences of data of a model in dataframe with `model.get_influence().summary_frame()`\n",
    "- Cook's distance is the most common measure of influence.\n",
    "- `cooks_d` in `summary_frame()` stores the influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ols(\"y_var ~ x_var\", data=df).fit()\n",
    "# df_summary = model.get_influence().summary_frame()\n",
    "# df[\"leverage\"] = df_summary[\"hat_diag\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
